{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.0176e-01,  3.7057e-01,  2.1281e-02, -3.4125e-01,  4.9538e-02,\n",
       "        2.9440e-01, -1.7376e-01, -2.7982e-01,  6.7622e-02,  2.1693e+00,\n",
       "       -6.2691e-01,  2.9106e-01, -6.7270e-01,  2.3319e-01, -3.4264e-01,\n",
       "        1.8311e-01,  5.0226e-01,  1.0689e+00,  1.4698e-01, -4.5230e-01,\n",
       "       -4.1827e-01, -1.5967e-01,  2.6748e-01, -4.8867e-01,  3.6462e-01,\n",
       "       -4.3403e-02, -2.4474e-01, -4.1752e-01,  8.9088e-02, -2.5552e-01,\n",
       "       -5.5695e-01,  1.2243e-01, -8.3526e-02,  5.5095e-01,  3.6410e-01,\n",
       "        1.5361e-01,  5.5738e-01, -9.0702e-01, -4.9098e-02,  3.8580e-01,\n",
       "        3.8000e-01,  1.4425e-01, -2.7221e-01, -3.7016e-01, -1.2904e-01,\n",
       "       -1.5085e-01, -3.8076e-01,  4.9583e-02,  1.2755e-01, -8.2788e-02,\n",
       "        1.4339e-01,  3.2537e-01,  2.7226e-01,  4.3632e-01, -3.1769e-01,\n",
       "        7.9405e-01,  2.6529e-01,  1.0135e-01, -3.3279e-01,  4.3117e-01,\n",
       "        1.6687e-01,  1.0729e-01,  8.9418e-02,  2.8635e-01,  4.0117e-01,\n",
       "       -3.9222e-01,  4.5217e-01,  1.3521e-01, -2.8878e-01, -2.2819e-02,\n",
       "       -3.4975e-01, -2.2996e-01,  2.0224e-01, -2.1177e-01,  2.7184e-01,\n",
       "        9.1703e-02, -2.0610e-01, -6.5758e-01,  1.8949e-01, -2.6756e-01,\n",
       "        9.2639e-02,  4.3316e-01, -4.8868e-01, -3.8309e-01, -2.1910e-01,\n",
       "       -4.4183e-01,  9.8044e-01,  6.7423e-01,  8.4003e-01, -1.8169e-01,\n",
       "        1.7385e-01,  4.1848e-01,  1.6098e-01, -1.0490e-01, -4.1965e-01,\n",
       "       -3.5660e-01, -1.6837e-01, -6.3458e-01,  3.8422e-01, -3.5043e-01,\n",
       "        1.7486e-01,  5.3528e-01,  2.0143e-01,  3.7877e-02,  4.7105e-01,\n",
       "       -4.4344e-01,  1.6840e-01, -1.6685e-01, -2.4022e-01, -1.0077e-01,\n",
       "        3.0334e-01,  4.2730e-01,  3.3803e-01, -4.3481e-01,  1.1343e-01,\n",
       "        6.1958e-02,  6.1808e-02, -1.4007e-01,  8.2018e-02, -3.9130e-02,\n",
       "        5.1442e-02,  2.8725e-01,  5.8025e-01, -5.7641e-01, -3.4652e-01,\n",
       "        1.0132e-01,  1.4463e-01,  1.1569e-02, -3.3701e-01, -1.7586e-01,\n",
       "       -3.5724e-01, -2.1423e-01,  1.1429e-02,  4.7645e-01, -3.7463e-02,\n",
       "       -2.9488e-01, -1.7465e-01,  3.0255e-01,  6.0317e-01, -6.6790e-02,\n",
       "       -2.7050e+00, -7.0308e-01,  4.0548e-01,  6.2874e-01,  6.3080e-01,\n",
       "       -5.4513e-01, -9.6191e-03,  2.6533e-01,  2.3391e-01, -5.1886e-02,\n",
       "       -6.5759e-03,  1.8573e-02, -4.5693e-01, -7.0351e-02, -3.0621e-01,\n",
       "       -1.4018e-02, -2.0408e-01,  3.7100e-01, -3.2354e-01, -8.4646e-01,\n",
       "        2.7092e-01, -1.1961e-01, -9.5576e-02, -6.0464e-01,  4.2409e-02,\n",
       "        2.4656e-01,  3.8445e-02, -2.5467e-02, -9.2908e-02, -2.1356e-01,\n",
       "        3.6120e-01,  1.9113e-02,  6.2741e-02, -1.3083e-01, -1.5146e-03,\n",
       "        5.8238e-01, -1.8956e-01,  7.8105e-01,  1.0477e-02,  1.0928e+00,\n",
       "        1.0140e-01, -3.6248e-01, -1.1962e-01, -3.4462e-01, -5.5704e-01,\n",
       "        2.5797e-01,  3.3356e-01,  3.3194e-01, -3.1298e-01, -7.5547e-01,\n",
       "       -7.5290e-01, -9.3072e-02, -1.1173e-01, -5.7251e-01,  1.6639e-01,\n",
       "        6.3579e-01,  2.4006e-01, -2.9211e-01,  9.0182e-01,  1.2425e-01,\n",
       "       -5.7751e-01,  4.7986e-02, -4.2748e-01,  2.4446e-01,  4.7232e-02,\n",
       "        3.5694e-01,  4.4241e-01, -2.3055e-01,  6.6037e-01, -7.3983e-03,\n",
       "       -3.7857e-01,  2.2759e-01, -3.7138e-01,  3.1055e-01, -7.2105e-02,\n",
       "       -2.4490e-01, -3.9761e-02,  5.3650e-01, -4.1478e-01,  1.6563e-01,\n",
       "        3.3707e-01,  1.0920e-01,  3.7219e-01, -5.5727e-01, -7.8060e-01,\n",
       "        1.4251e-01, -3.5828e-01,  4.1638e-01,  2.1446e-01,  1.8410e-01,\n",
       "       -4.7704e-01, -2.2005e-02, -2.3634e-01, -2.2840e-01,  3.4722e-01,\n",
       "        2.3667e-01,  7.4249e-02, -8.8416e-02,  2.8618e-01, -4.6942e-01,\n",
       "       -4.3914e-01, -2.6474e-01, -3.0690e-01, -1.5260e-01, -8.4870e-02,\n",
       "        2.8410e-01, -1.8481e-01, -2.2122e-01, -1.1169e-01, -2.5241e-02,\n",
       "        4.5968e-02,  3.5343e-02,  2.2467e-01,  5.1556e-01, -6.5137e-04,\n",
       "        9.9559e-02, -1.4215e-01,  2.0136e-01,  2.8334e-01, -2.8772e-01,\n",
       "        3.7766e-02, -3.7608e-01, -1.1681e-01, -6.7020e-01, -4.6265e-02,\n",
       "        3.8784e-01, -3.2295e-02, -5.4291e-02, -4.5384e-01,  1.9552e-01,\n",
       "       -2.9470e-01,  8.5009e-01,  1.0345e-01,  9.7010e-02,  1.1339e-01,\n",
       "        3.9502e-01,  5.9043e-02,  2.1978e-01,  1.8845e-01, -1.5891e-01,\n",
       "       -1.0301e-01,  3.3164e-01,  6.1477e-02, -2.9848e-01,  4.4510e-01,\n",
       "        4.7329e-01,  2.6312e-01, -1.8495e-01,  1.4652e-01, -3.1510e-02,\n",
       "        2.2908e-02, -2.5929e-01, -3.0862e-01,  1.7545e-03, -1.8962e-01,\n",
       "        5.4789e-01,  3.1194e-01,  2.4693e-01,  2.9929e-01, -7.4861e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'dog').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.96635887e-01, -2.32740352e-03, -5.36607020e-02, -6.10564947e-02,\n",
       "       -4.08843048e-02,  1.45266443e-01, -1.08268000e-01, -6.27789786e-03,\n",
       "        1.48455709e-01,  1.90697408e+00, -2.57692993e-01, -1.95818534e-03,\n",
       "       -1.16141019e-02, -1.62858292e-01, -1.62938282e-01,  1.18210977e-02,\n",
       "        5.12646027e-02,  1.00078702e+00, -2.01447997e-02, -2.54611671e-01,\n",
       "       -1.28316596e-01, -1.97198763e-02, -2.89733019e-02, -1.94347113e-01,\n",
       "        1.26644447e-01, -8.69869068e-02, -2.20812604e-01, -1.58452198e-01,\n",
       "        9.86308008e-02, -1.79210991e-01, -1.55290633e-01,  1.95643142e-01,\n",
       "        2.66436003e-02, -1.64984968e-02,  1.18824698e-01, -1.17830629e-03,\n",
       "        4.99809943e-02, -4.23077159e-02, -3.86111848e-02, -7.47400150e-03,\n",
       "        1.23448208e-01,  9.60620027e-03, -3.32463719e-02, -1.77848607e-01,\n",
       "        1.19390726e-01,  1.87545009e-02, -1.84173390e-01,  6.91781715e-02,\n",
       "        1.28520593e-01,  1.48827005e-02, -1.78013414e-01,  1.10003807e-01,\n",
       "       -3.35464999e-02, -1.52476998e-02, -9.41195935e-02,  1.58633105e-02,\n",
       "       -1.29811959e-02,  1.40140295e-01, -1.47720069e-01, -3.81718054e-02,\n",
       "        4.66808230e-02,  3.31423879e-02,  7.97965974e-02,  1.60014004e-01,\n",
       "        8.90410226e-03, -1.01237908e-01,  7.39663988e-02,  2.47380026e-02,\n",
       "        4.26153988e-02,  9.66729969e-02,  2.87616011e-02,  7.22841993e-02,\n",
       "        1.76565602e-01,  7.55538046e-02,  1.10501610e-01, -1.02358103e-01,\n",
       "       -5.43345436e-02, -4.12176028e-02,  3.98623049e-02, -2.98339734e-03,\n",
       "       -5.32988012e-02,  1.90624595e-01, -6.42587021e-02, -1.76225007e-02,\n",
       "        3.94165330e-02, -1.14773512e-01,  4.25241649e-01,  2.07243040e-01,\n",
       "        2.60730416e-01,  1.31226778e-01, -8.00508037e-02,  6.88939020e-02,\n",
       "        7.05293044e-02, -1.10744104e-01,  4.14580032e-02,  5.13269613e-03,\n",
       "       -1.29179001e-01, -5.84542975e-02,  9.13560018e-02, -1.75975591e-01,\n",
       "        9.52741057e-02,  1.37699964e-02, -1.30865201e-01, -4.76420000e-02,\n",
       "        1.61670998e-01, -6.76959991e-01,  2.68619388e-01, -7.94106945e-02,\n",
       "        8.56394917e-02, -5.94138019e-02,  7.44821057e-02, -1.67490095e-01,\n",
       "        1.97447598e-01, -2.71580786e-01,  1.51915969e-02,  1.12019002e-01,\n",
       "       -4.32585999e-02, -1.03554968e-02,  6.33272156e-02,  5.20200143e-03,\n",
       "        4.94491048e-02, -1.07016601e-01, -6.45387918e-02, -1.76269561e-01,\n",
       "       -1.98135704e-01,  4.17800918e-02,  1.23686995e-02, -1.13280594e-01,\n",
       "       -4.03523073e-02, -4.21132054e-03, -9.65667963e-02, -7.12300017e-02,\n",
       "       -2.19088510e-01,  6.41715974e-02,  1.11634992e-01, -7.12868944e-02,\n",
       "       -8.27060193e-02,  1.53889004e-02,  6.84699565e-02, -5.50561920e-02,\n",
       "       -1.84788990e+00, -4.75010052e-02,  1.31487206e-01,  1.03359401e-01,\n",
       "        1.80857688e-01, -8.03041980e-02,  2.27739997e-02,  5.56868985e-02,\n",
       "        9.20986086e-02,  6.22248054e-02,  4.86670025e-02, -4.06427011e-02,\n",
       "        3.83703932e-02, -4.05869968e-02, -2.26339817e-01,  3.69174965e-02,\n",
       "       -1.30066186e-01,  1.27621710e-01,  2.76701003e-02, -1.39992401e-01,\n",
       "       -3.75526994e-02, -8.11104029e-02, -1.78196102e-01, -1.21652998e-01,\n",
       "       -5.88919744e-02, -1.06128812e-01, -4.72390745e-03, -1.14130601e-01,\n",
       "       -7.60087445e-02, -9.48704034e-02,  1.68780401e-01,  3.82669941e-02,\n",
       "       -1.68303996e-01, -1.30991384e-01, -2.46409744e-01,  1.42855030e-02,\n",
       "        1.23633012e-01,  7.95699935e-03, -3.22283022e-02,  3.75844017e-02,\n",
       "       -4.48104031e-02, -2.00578898e-01, -2.86081016e-01, -1.83181003e-01,\n",
       "       -5.46899159e-04,  6.52990937e-02,  2.34263036e-02, -7.60660022e-02,\n",
       "        1.13897599e-01, -7.05380812e-02,  1.30277812e-01,  2.83973999e-02,\n",
       "        1.73887815e-02, -1.71358977e-02,  1.78455990e-02,  1.86773703e-01,\n",
       "        1.83613986e-01, -4.05438878e-02,  1.28929759e-03, -3.71900201e-03,\n",
       "       -1.97373003e-01,  4.78463694e-02, -2.21408010e-01,  2.68826094e-02,\n",
       "        2.40951017e-01,  7.42616802e-02,  7.53984973e-02, -7.67349079e-02,\n",
       "       -5.37766796e-03, -8.06540065e-03,  1.88790001e-02,  8.31135064e-02,\n",
       "       -5.20760007e-02,  1.29393607e-01,  4.09864075e-02,  7.31946975e-02,\n",
       "       -1.64099425e-01,  1.17529690e-01, -6.96440935e-02,  1.91028208e-01,\n",
       "        1.01721905e-01,  6.34808987e-02, -8.29815865e-02, -6.95784390e-03,\n",
       "       -1.69757873e-01, -2.02478573e-01,  3.65395918e-02,  1.32345587e-01,\n",
       "        3.53013016e-02,  2.27603033e-01, -1.52753398e-01,  7.80210178e-03,\n",
       "        2.06879750e-02, -8.63540452e-03,  9.85722095e-02, -2.91380938e-02,\n",
       "       -1.42988954e-02, -9.39018354e-02,  1.43968105e-01,  7.82396942e-02,\n",
       "       -1.93540990e-01, -9.36544985e-02, -8.23533013e-02,  4.40272018e-02,\n",
       "       -2.22195080e-03, -1.29856914e-01, -1.53841600e-01, -1.55329984e-02,\n",
       "       -2.55266696e-01,  1.14425398e-01, -1.03161987e-02, -4.66439016e-02,\n",
       "       -5.69390282e-02,  7.72780031e-02,  1.28908500e-01,  1.61679000e-01,\n",
       "        1.50837511e-01,  6.18334934e-02, -9.06937942e-02, -3.52137014e-02,\n",
       "        1.35956988e-01,  7.52059072e-02,  5.73905036e-02, -1.65402606e-01,\n",
       "        1.68419987e-01, -1.83722824e-01,  5.91069926e-03, -1.25354990e-01,\n",
       "        3.95771042e-02,  5.67352995e-02, -5.63519308e-03,  1.53597593e-01,\n",
       "       -6.84822723e-02, -1.40976995e-01, -3.62732522e-02, -2.61475928e-02,\n",
       "        2.50091963e-02,  1.18994810e-01, -2.66857035e-02,  7.50442073e-02,\n",
       "        2.04583794e-01,  4.37736101e-02, -8.17096978e-02,  6.80228025e-02,\n",
       "        5.50465994e-02, -2.39979066e-02,  7.68290013e-02, -5.76773956e-02,\n",
       "        8.30340981e-02,  3.63199934e-02, -1.65820405e-01,  2.55408939e-02,\n",
       "       -5.30679002e-02, -1.35961995e-01, -1.03501797e-01,  1.36406809e-01,\n",
       "        9.66293067e-02,  7.33902007e-02, -1.83055893e-01, -2.73141060e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'The quick brown fox jumped over the lazy dogs.')\n",
    "\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying similar vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion lion 1.0\n",
      "lion cat 0.52654374\n",
      "lion pet 0.39923766\n",
      "cat lion 0.52654374\n",
      "cat cat 1.0\n",
      "cat pet 0.7505456\n",
      "pet lion 0.39923766\n",
      "pet cat 0.7505456\n",
      "pet pet 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a three-token Doc object:\n",
    "tokens = nlp(u'lion cat pet')\n",
    "\n",
    "# Iterate through token combinations:\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "kooble False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "# Vector norms\n",
    "# It's sometimes helpful to aggregate 300 dimensions into a Euclidian (L2) norm, computed as the square root of the sum-of-squared-vectors. This is accessible as the .vector_norm token attribute. Other helpful attributes include .has_vector and .is_oov or out of vocabulary.\n",
    "\n",
    "# For example, our 685k vector library may not have the word \"kooble\". To test this:\n",
    "\n",
    "tokens = nlp(u'dog cat kooble')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n",
    "\n",
    "# We see that \"kooble\" does not have a vector, so the vector_norm value is zero, and it identifies as out of vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector arithmetic\n",
    "\n",
    "We can calculate new vectors by adding & subtracting related vectors. Like - \n",
    "\n",
    "\"king\" - \"man\" + \"woman\" = \"queen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'woman', 'she', 'lion', 'who', 'fox', 'brown', 'when', 'dare', 'cat']\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "\n",
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "\n",
    "# Now we find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
    "new_vector = king - man + woman\n",
    "computed_similarities = []\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    # Ignore words without vectors and mixed-case words:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(new_vector, word.vector)\n",
    "                computed_similarities.append((word, similarity))\n",
    "\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "\n",
    "print([w[0].text for w in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broad Steps:\n",
    "-First, consider the text being analyzed. A model trained on paragraph-long movie reviews might not be effective on tweets. Make sure to use an appropriate model for the task at hand.\n",
    "\n",
    "-Next, decide the type of analysis to perform. In the previous section on text classification we used a bag-of-words technique that considered only single tokens, or unigrams. Some rudimentary sentiment analysis models go one step further, and consider two-word combinations, or bigrams. In this section, we'd like to work with complete sentences, and for this we're going to import a trained NLTK lexicon called VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK's VADER module\n",
    "\n",
    "VADER is an NLTK module that provides sentiment scores based on words used (\"completely\" boosts a score, while \"slightly\" reduces it), on capitalization & punctuation (\"GREAT!!!\" is stronger than \"great.\"), and negations (words like \"isn't\" and \"doesn't\" affect the outcome)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER's SentimentIntensityAnalyzer() takes in a string and returns a dictionary of scores in each of four categories:\n",
    "\n",
    "* negative\n",
    "* neutral\n",
    "* positive\n",
    "* compound (computed by normalizing the scores above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.2023}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'This was a fine movie.'\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.388, 'pos': 0.612, 'compound': 0.8877}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'This was the best, most awesome movie EVERRR!!!'\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.369, 'neu': 0.631, 'pos': 0.0, 'compound': -0.6249}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'This was the worst movie of all times.'\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using VADER to analyze Amazon Reviews\n",
    "\n",
    "For this we are going to apply SentimentIntensityAnalyzer to a dataset of 10,000 Amazon reviews. The documents are labeled as either \"pos\" or \"neg\". At the end we'll determine the accuracy of our sentiment analysis with VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...\n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...\n",
       "2   pos  Amazing!: This soundtrack is my favorite music...\n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...\n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('amazonreviews.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5097\n",
       "pos    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data:\n",
    "\n",
    "Let's check to see if any empty records exist in amazonreviews.tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE NaN VALUES AND EMPTY STRINGS:\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,lb,rv in df.itertuples():  # iterate over the DataFrame\n",
    "    if type(rv)==str:            # avoid NaN values\n",
    "        if rv.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "\n",
    "df.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5097\n",
       "pos    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the first review through VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'compound': 0.9454}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(df.loc[0]['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our first review was labeled \"positive\", and earned a positive compound score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Scores and Labels to the DataFrame\n",
    "In this next section we'll add columns to the original DataFrame to store polarity_score dictionaries, extracted compound scores, and new \"pos/neg\" labels derived from the compound score. We'll use this last column to perform an accuracy test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454        pos  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957        pos  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858        pos  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814        pos  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781        pos  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report on Accuracy\n",
    "Finally, we'll use scikit-learn to determine how close VADER came to our original 10,000 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7091"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['label'],df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.51      0.64      5097\n",
      "         pos       0.64      0.91      0.75      4903\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['label'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2622 2475]\n",
      " [ 434 4469]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df['label'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that VADER correctly identified an Amazon review as \"positive\" or \"negative\" roughly *71%* of the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
